# ThoughtLab Dependency Analysis & Gap Assessment

**Date**: 2026-01-25
**Purpose**: Identify existing dependencies vs required tools for scientific algorithms

---

## ğŸ“Š Current Dependency Inventory

### Backend (Python)
```
âœ… INSTALLED:
â”œâ”€ Neo4j Driver: 6.0.3 âœ“ (Recent, excellent)
â”œâ”€ NumPy: 2.3.5 âœ“ (Essential for ML)
â”œâ”€ SciPy: 1.16.3 âœ“ (Statistical functions)
â”œâ”€ FastAPI: 0.121.0+ âœ“ (Web framework)
â”œâ”€ Uvicorn: 0.32.0+ âœ“ (ASGI server)
â”œâ”€ Redis: 5.0.0+ âœ“ (Caching)
â”œâ”€ Pydantic: 2.6.0+ âœ“ (Validation)
â”œâ”€ httpx: 0.26.0+ âœ“ (HTTP client)
â”œâ”€ pytest: 8.0.0+ âœ“ (Testing)
â””â”€ python-dotenv: 1.0.0+ âœ“ (Config)

âŒ NOT INSTALLED:
â”œâ”€ PyTorch: âŒ (Required for ML)
â”œâ”€ LangChain: âŒ (AI framework)
â”œâ”€ Transformers: âŒ (BERT models)
â”œâ”€ PyTorch Geometric: âŒ (GNNs)
â”œâ”€ scikit-learn: âŒ (ML utilities)
â”œâ”€ spacy: âŒ (NLP/NER)
â”œâ”€ scipy: âœ… (Already installed!)
â”œâ”€ scikit-learn: âŒ (ML utilities)
â”œâ”€ wandb: âŒ (Experiment tracking)
â”œâ”€ optuna: âŒ (Hyperparameter optimization)
â””â”€ pyro-ppl: âŒ (Bayesian inference)
```

### Frontend (Node.js)
```
âœ… INSTALLED:
â”œâ”€ React: 18.3.1 âœ“ (UI framework)
â”œâ”€ TypeScript: 5.7.2 âœ“ (Type safety)
â”œâ”€ Vite: 5.4.21 âœ“ (Build tool)
â”œâ”€ Cytoscape: 3.31.0 âœ“ (Graph visualization)
â”œâ”€ TanStack Query: 5.62.11 âœ“ (Server state)
â”œâ”€ Axios: 1.7.9 âœ“ (HTTP client)
â”œâ”€ Tailwind CSS: 3.4.17 âœ“ (Styling)
â””â”€ Vitest: 2.1.8 âœ“ (Testing)

âŒ NOT INSTALLED (for ML viz):
â”œâ”€ TensorFlow.js: âŒ (Browser ML - optional)
â”œâ”€ D3.js: âŒ (Advanced visualization - optional)
â””â”€ Plotly.js: âŒ (Charts - optional)
```

---

## ğŸ¯ Gap Analysis by Phase

### Phase 1: Foundation (Week 1-2)
**Required for HNSW indexing**:
- âœ… Neo4j 5.13+ (Have 6.0.3) - **READY**
- âœ… Python 3.11+ (Have 3.13) - **READY**
- âœ… NumPy (Have 2.3.5) - **READY**

**Required for Beta uncertainty**:
- âœ… Python math - **READY**
- âœ… SciPy (Have 1.16.3) - **READY** (for Beta distribution)
- âœ… NumPy (Have 2.3.5) - **READY**

**Required for Neo4j GDS**:
- âœ… Neo4j 5.13+ Enterprise (Have 6.0.3) - **READY**
- âš ï¸ GDS Plugin - Need to check
- âœ… Neo4j driver (Have 6.0.3) - **READY**

**Required for calibration**:
- âœ… NumPy (Have 2.3.5) - **READY**
- âœ… SciPy (Have 1.16.3) - **READY**
- âš ï¸ scikit-learn (for temperature scaling) - **MISSING**

**Phase 1 Status**: âœ… **90% READY**
- Only missing: scikit-learn (easy install)
- GDS plugin check needed

---

### Phase 2: Intelligence (Month 1)
**Required for BERT fine-tuning**:
- âŒ PyTorch - **MISSING** (Major)
- âŒ Transformers (HuggingFace) - **MISSING** (Major)
- âŒ scikit-learn - **MISSING** (Easy)
- âœ… NumPy - **READY**
- âš ï¸ GPU recommended (RTX 3090 or similar) - **CHECK**

**Required for ComplEx embeddings**:
- âŒ PyTorch - **MISSING** (Major)
- âŒ scikit-learn - **MISSING** (Easy)
- âœ… NumPy - **READY**
- âœ… SciPy - **READY**

**Required for A/B testing**:
- âš ï¸ wandb (optional) or MLflow - **MISSING** (Easy)
- âœ… Existing: Manual tracking possible

**Phase 2 Status**: âš ï¸ **40% READY**
- Missing: PyTorch, Transformers (core ML libraries)
- Need: GPU for training
- Easy wins: scikit-learn, wandb

---

### Phase 3: Advanced (Month 2-3)
**Required for RGCN**:
- âŒ PyTorch - **MISSING**
- âŒ PyTorch Geometric - **MISSING**
- âŒ scikit-learn - **MISSING**
- âœ… NumPy - **READY**
- âš ï¸ GPU recommended - **CHECK**

**Required for Active Learning**:
- âŒ PyTorch - **MISSING**
- âŒ scikit-learn - **MISSING**
- âš ï¸ wandb/optuna - **MISSING**

**Required for Bayesian methods**:
- âŒ Pyro/Pyro-ppl (Bayesian) - **MISSING**
- âŒ PyTorch - **MISSING**
- âœ… SciPy - **READY**

**Phase 3 Status**: ğŸš§ **30% READY**
- Missing: PyTorch, PyTorch Geometric, Pyro
- Need: GPU resources
- Complex: Bayesian inference setup

---

### Phase 4: Production (Month 4-6)
**Required for scale**:
- âš ï¸ Distributed training - **MISSING** (infrastructure)
- âš ï¸ MLOps tools - **MISSING** (wandb, MLflow)
- âœ… Existing: Basic infrastructure in place

**Required for research**:
- âŒ Advanced libraries - **MISSING**
- âš ï¸ Publication tools - **MISSING**
- âœ… Existing: Strong foundation

**Phase 4 Status**: ğŸš§ **50% READY**
- Need: Infrastructure scaling
- Need: MLOps pipeline
- Need: Research tools

---

## ğŸ“‹ Installation Priority Matrix

### P0: Phase 1 (Week 1) - Critical
| Package | Why | Install Command | Priority |
|---------|-----|-----------------|----------|
| **scikit-learn** | Calibration, ML utilities | `uv add scikit-learn` | ğŸ”´ Critical |
| **pytorch** | Foundation for all ML | `uv add torch --extra-index-url` | ğŸ”´ Critical |
| **transformers** | BERT models for NER/RE | `uv add transformers` | ğŸ”´ Critical |

### P1: Phase 2 (Month 1) - Important
| Package | Why | Install Command | Priority |
|---------|-----|-----------------|----------|
| **torch-geometric** | GNNs (RGCN) | `uv add torch-geometric` | ğŸŸ¡ High |
| **wandb** | Experiment tracking | `uv add wandb` | ğŸŸ¡ Medium |
| **spacy** | Alternative NER | `uv add spacy` | ğŸŸ¢ Low |

### P2: Phase 3 (Month 2-3) - Advanced
| Package | Why | Install Command | Priority |
|---------|-----|-----------------|----------|
| **pyro-ppl** | Bayesian inference | `uv add pyro-ppl` | ğŸŸ¡ Medium |
| **optuna** | Hyperparameter opt | `uv add optuna` | ğŸŸ¡ Medium |
| **dgl** | Alternative GNN lib | `uv add dgl` | ğŸŸ¢ Low |

### P3: Phase 4 (Month 4-6) - Optimization
| Package | Why | Install Command | Priority |
|---------|-----|-----------------|----------|
| **mlflow** | MLOps pipeline | `uv add mlflow` | ğŸŸ¡ Medium |
| **ray** | Distributed training | `uv add ray` | ğŸŸ¢ Low |
| **knockknock** | Training alerts | `uv add knockknock` | ğŸŸ¢ Low |

---

## ğŸ”§ Installation Commands

### For Phase 1 (Week 1)
```bash
# Activate virtual environment
cd backend
source .venv/bin/activate  # Linux/Mac
# or
.venv\Scripts\activate  # Windows

# Install critical packages (5 minutes)
uv add scikit-learn
uv add pytorch --extra-index-url https://download.pytorch.org/whl/cpu  # CPU version
uv add transformers

# Verify installations
python -c "import sklearn; print('scikit-learn:', sklearn.__version__)"
python -c "import torch; print('PyTorch:', torch.__version__)"
python -c "from transformers import pipeline; print('Transformers: OK')"
```

### For Phase 2 (Month 1)
```bash
# Additional packages
uv add torch-geometric
uv add wandb
uv add optuna

# Verify
python -c "import torch_geometric; print('PyG:', torch_geometric.__version__)"
```

### For Phase 3 (Month 2-3)
```bash
# Advanced packages
uv add pyro-ppl
uv add dgl -f https://data.dgl.ai/wheels/torch2.2/cpu/repo.html

# Verify
python -c "import pyro; print('Pyro: OK')"
```

---

## ğŸ’» Hardware Requirements

### Current Setup Check
```bash
# Check CPU
python -c "import multiprocessing; print(f'CPU Cores: {multiprocessing.cpu_count()}')"

# Check RAM
import psutil
print(f"RAM: {psutil.virtual_memory().total / 1e9:.1f} GB")
```

### Phase 1 Requirements
- **CPU**: 4+ cores (likely OK)
- **RAM**: 8+ GB (likely OK)
- **GPU**: Not required
- **Storage**: 50 GB (likely OK)

### Phase 2 Requirements
- **CPU**: 8+ cores (check)
- **RAM**: 16+ GB (check)
- **GPU**: Recommended (RTX 3090 or similar)
- **Storage**: 100 GB (check)

### Phase 3 Requirements
- **CPU**: 16+ cores (may need upgrade)
- **RAM**: 32+ GB (may need upgrade)
- **GPU**: Required (2Ã— RTX 3090 or A100)
- **Storage**: 200 GB (check)

### Phase 4 Requirements
- **CPU**: 32+ cores (cloud recommended)
- **RAM**: 64+ GB (cloud recommended)
- **GPU**: 4Ã— A100 (cloud recommended)
- **Storage**: 500 GB+ (cloud recommended)

---

## ğŸ¯ Quick Wins (Minimal Install)

### Option 1: Minimal Phase 1 (2 hours)
```bash
# Just what's needed for Week 1
uv add scikit-learn
uv add pytorch --extra-index-url https://download.pytorch.org/whl/cpu

# Total: 2 packages, ~2GB download
```
**Impact**: 90% of Phase 1 value

### Option 2: Phase 1 + 2 Basics (4 hours)
```bash
# Phase 1 + BERT fine-tuning basics
uv add scikit-learn
uv add pytorch --extra-index-url https://download.pytorch.org/whl/cpu
uv add transformers
uv add torch-geometric

# Total: 4 packages, ~5GB download
```
**Impact**: 90% of Phase 1 + 80% of Phase 2 value

### Option 3: Full Phase 1-2 (6 hours)
```bash
# All Phase 1-2 requirements
uv add scikit-learn
uv add pytorch --extra-index-url https://download.pytorch.org/whl/cpu
uv add transformers
uv add torch-geometric
uv add wandb
uv add optuna
uv add pyro-ppl

# Total: 7 packages, ~6GB download
```
**Impact**: 100% of Phase 1-2 value + Phase 3 basics

---

## ğŸ” Neo4j GDS Check

### Check if GDS Plugin is Available
```bash
# Run in Neo4j Browser
RETURN gds.version();

# Or via Cypher shell
cypher-shell "RETURN gds.version();"
```

### If Not Available, Enable It
```bash
# Update docker-compose.yml
services:
  neo4j:
    image: neo4j:5.13.0-enterprise  # or 6.0.0-enterprise
    environment:
      - NEO4J_ACCEPT_LICENSE_AGREEMENT=yes
      - NEO4J_PLUGINS=["graph-data-science"]  # Add this line
```

### Verify Installation
```bash
# After restart
cypher-shell "RETURN gds.version();"

# Should return: 2.x.x
```

---

## ğŸš€ Recommended Installation Order

### Today (30 minutes)
1. âœ… Check Neo4j version (done: 6.0.3)
2. âœ… Check Neo4j GDS plugin
3. âš ï¸ Install scikit-learn
4. âš ï¸ Install PyTorch (CPU version first)

### This Week (4 hours)
1. âš ï¸ Install transformers
2. âš ï¸ Install torch-geometric
3. âš ï¸ Test with Phase 1 algorithms
4. âš ï¸ Set up experiment tracking

### Month 1 (1-2 days)
1. âš ï¸ Install full ML stack
2. âš ï¸ Test BERT fine-tuning
3. âš ï¸ Set up GPU environment
4. âš ï¸ Run first ML experiments

---

## ğŸ’° Cost Estimates

### Software Costs (All Free/Open Source)
- **PyTorch**: Free
- **Transformers**: Free
- **scikit-learn**: Free
- **PyTorch Geometric**: Free
- **wandb**: Free tier available
- **MLflow**: Free/Open Source

### Hardware Costs (If Upgrading)
```
Local Development:
- GPU (RTX 3090): $1,500-2,000 (one-time)
- RAM upgrade (16â†’32 GB): $100-200
- Total: $1,600-2,200

Cloud (Alternative):
- AWS g4dn.xlarge (T4 GPU): $0.526/hr
- Google Colab Pro: $9.99/month
- RunPod.io: $0.20-0.80/hr
```

### Team Time Costs
```
Installation & Setup:
- Phase 1: 4 hours Ã— $100/hr = $400
- Phase 2: 16 hours Ã— $100/hr = $1,600
- Phase 3: 40 hours Ã— $100/hr = $4,000
- Total Setup: ~$6,000

Ongoing (6 months):
- 20% FTE ML Engineer: ~$60,000
- Infrastructure: $2,000-5,000
```

---

## ğŸ“ Learning Requirements

### Team Skills Assessment
**Current** (likely):
- âœ… Python programming
- âœ… FastAPI/REST APIs
- âœ… Neo4j/Cypher
- âœ… Basic statistics
- âœ… Git/version control

**Required for ML** (to learn):
- âš ï¸ PyTorch/TensorFlow
- âš ï¸ Deep learning fundamentals
- âš ï¸ Graph neural networks
- âš ï¸ Bayesian statistics
- âš ï¸ MLOps practices

### Learning Timeline
```
Week 1-2: PyTorch basics (8 hours)
Month 1: GNNs + Transformers (20 hours)
Month 2: Bayesian methods (16 hours)
Month 3: MLOps + Advanced topics (20 hours)
Total: ~64 hours per team member
```

---

## ğŸ“Š Summary: Current vs Required

### What We Have âœ…
```
Core Infrastructure:
âœ“ Neo4j 6.0.3 (excellent)
âœ“ FastAPI/Backend
âœ“ React/Frontend
âœ“ Redis cache
âœ“ Basic ML: NumPy, SciPy

Mathematical Foundations:
âœ“ Linear algebra (NumPy)
âœ“ Statistics (SciPy)
âœ“ Probability (SciPy)

Development Tools:
âœ“ Testing (pytest)
âœ“ Type checking (Pydantic)
âœ“ Build tools (uv)
```

### What We Need âš ï¸
```
Machine Learning:
âœ— PyTorch (core requirement)
âœ— Transformers (BERT models)
âœ— scikit-learn (utilities)
âœ— PyTorch Geometric (GNNs)

Advanced Methods:
âœ— Bayesian inference (Pyro)
âœ— Hyperparameter optimization (optuna)
âœ— Experiment tracking (wandb/MLflow)

Hardware:
? GPU for training (RTX 3090 or cloud)
? More RAM (16-32 GB recommended)
? Storage (50-200 GB depending on phase)

Team Knowledge:
? Deep learning fundamentals
? Graph neural networks
? Bayesian statistics
? MLOps practices
```

### Installation Difficulty
- **Easy** (5 minutes): scikit-learn, wandb
- **Medium** (30 minutes): PyTorch, transformers
- **Hard** (1-2 hours): PyTorch Geometric, CUDA setup
- **Complex** (1 day): Full MLOps pipeline

---

## ğŸ¯ Immediate Action Plan

### Today (1 hour)
1. [ ] Check Neo4j GDS plugin availability
2. [ ] Install scikit-learn: `uv add scikit-learn`
3. [ ] Install PyTorch CPU: `uv add torch --extra-index-url https://download.pytorch.org/whl/cpu`
4. [ ] Test installations work
5. [ ] Plan GPU acquisition if needed

### This Week (4 hours)
1. [ ] Install transformers: `uv add transformers`
2. [ ] Test with a simple BERT model
3. [ ] Set up wandb account for tracking
4. [ ] Install Phase 2 dependencies
5. [ ] Run Phase 1 algorithms to test

### Month 1 (1-2 days)
1. [ ] Assess GPU needs based on testing
2. [ ] Purchase GPU or set up cloud account
3. [ ] Install PyTorch Geometric
4. [ ] Run BERT fine-tuning test
5. [ ] Set up experiment tracking
6. [ ] Plan Phase 3 dependencies

---

## ğŸ“ Getting Help

### Installation Issues
- **PyTorch**: Check https://pytorch.org/get-started/locally/
- **PyTorch Geometric**: https://pytorch-geometric.readthedocs.io/en/latest/install/
- **Transformers**: https://huggingface.co/docs/transformers/installation
- **Neo4j GDS**: https://neo4j.com/docs/graph-data-science/current/installation/

### Team Support
- Schedule pair programming for installation
- Use team learning sessions
- Share installation scripts
- Document common issues

### External Resources
- PyTorch tutorials: https://pytorch.org/tutorials/
- HuggingFace course: https://huggingface.co/learn
- Neo4j GDS docs: https://neo4j.com/docs/graph-data-science/
- Papers from research documents

---

## âœ… Success Criteria

### Installation Complete When:
1. âœ… scikit-learn imports without error
2. âœ… PyTorch basic operations work
3. âœ… Transformers can load a model
4. âœ… Neo4j GDS algorithms run
5. âœ… Phase 1 code executes successfully

### Phase 1 Ready When:
1. âœ… HNSW indexing deployed
2. âœ… Beta uncertainty tracking works
3. âœ… Neo4j GDS provides analytics
4. âœ… Calibration improves confidence scores

### Phase 2 Ready When:
1. âœ… BERT can be fine-tuned on sample data
2. âœ… ComplEx embeddings train successfully
3. âœ… User feedback loop integrated
4. âœ… A/B testing framework operational

---

**Next Step**: Check Neo4j GDS plugin availability, then install scikit-learn and PyTorch

**Estimated Time to Phase 1**: 1-2 hours (install + test)
**Estimated Time to Phase 2**: 1-2 days (install + basic tests)
**Total Time to Full Stack**: 1 week (install + validation)

---
**Document Version**: 1.0
**Last Updated**: 2026-01-25
**Status**: Gap Analysis Complete
**Next**: Installation & Testing