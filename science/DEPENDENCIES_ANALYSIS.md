# Dependencies Analysis for Scientific Implementation

**Analysis of current dependencies vs. requirements for Phase 1 implementation**

---

## ðŸ“Š Current Backend Dependencies

### Existing Packages (from `backend/pyproject.toml`)

```
[project]
dependencies = [
    "neo4j>=5.26.0",                    # âœ… Graph database with GDS
    "redis>=7.1.0",                     # âœ… Cache, message queue
    "fastmcp>=2.14.1",                  # âœ… MCP server
    "langchain>=1.2.0",                 # âœ… AI orchestration
    "langchain-openai>=1.1.0",          # âœ… OpenAI integration
    "langchain-neo4j>=0.6.0",           # âœ… Neo4j + LangChain
    "langgraph>=1.0.5",                 # âœ… Agent workflows
    "uvicorn[standard]>=0.32.0",        # âœ… ASGI server
    "fastapi>=0.121.0",                 # âœ… Web framework
    "httpx>=0.26.0",                    # âœ… HTTP client
    "pydantic-settings>=2.6.0",         # âœ… Settings management
    "pytest>=8.0.0",                    # âœ… Testing
    "pytest-asyncio>=0.23.0",           # âœ… Async testing
    "python-dotenv>=1.0.0",             # âœ… Environment management
]
```

### âœ… What We Already Have (GOOD!)

#### For Phase 1 Implementation:

1. **Neo4j 5.26.0+** âœ…
   - HNSW vector indexing: **SUPPORTED** (requires 5.13+)
   - Graph Data Science: **SUPPORTED** (requires plugin)
   - **Action**: Enable GDS plugin in docker-compose

2. **Redis 7.1.0+** âœ…
   - Can be used for caching similarity results
   - Can store uncertainty distributions
   - **Action**: Use for performance optimization

3. **LangChain/LangGraph** âœ…
   - Can integrate with our ML algorithms
   - Provides LLM integration for entity extraction
   - **Action**: Build on existing AI workflows

4. **FastAPI + Pydantic** âœ…
   - API endpoints for scientific algorithms
   - Type validation for all models
   - **Action**: Add new endpoints for confidence/scoring

---

## ðŸ§® What We Need to Add

### Phase 1 Requirements (Week 1-2)

#### For Beta Uncertainty Tracking:
```python
# Built-in Python - NO ADDITIONAL DEPENDENCIES NEEDED! ðŸŽ‰
import math
import json
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple
```

**Verdict**: âœ… **Already available** - Use standard library

#### For HNSW Similarity:
```python
# Basic math operations - BUILT-IN ðŸŽ‰
import numpy as np  # âŒ NEEDED
import heapq
from collections import defaultdict
```

**Missing**: `numpy`

**Recommendation**: Add to dependencies
```toml
[project]
dependencies = [
    # ... existing ...
    "numpy>=1.24.0",
]
```

#### For Confidence Calibration:
```python
# Basic math - BUILT-IN ðŸŽ‰
import numpy as np  # âŒ NEEDED
from typing import Optional, Dict, Any
```

**Missing**: `numpy` (already identified)

**Optional** (for advanced calibration):
```toml
# For Platt scaling and isotonic regression
"scipy>=1.10.0",  # Optional, for optimization
```

#### For Graph Algorithms (Neo4j GDS):
```python
# Neo4j queries - BUILT-IN ðŸŽ‰
# Everything handled via Cypher queries
```

**Verdict**: âœ… **Already available** via Neo4j 5.26.0 + GDS plugin

---

### Phase 2 Requirements (Month 1)

#### For BERT Fine-tuning:
```python
# ML libraries - NEEDED
"torch>=2.1.0",              # PyTorch for training
"transformers>=4.35.0",      # HuggingFace BERT
"datasets>=2.14.0",          # Data handling
"scikit-learn>=1.3.0",       # Metrics, splitting
"accelerate>=0.24.0",        # Training optimization
```

**Recommendation**:
```toml
[project.optional-dependencies]
ml = [
    "torch>=2.1.0",
    "transformers>=4.35.0",
    "datasets>=2.14.0",
    "scikit-learn>=1.3.0",
    "accelerate>=0.24.0",
]
```

#### For ComplEx/RGCN Embeddings:
```python
# Graph ML - NEEDED
"torch>=2.1.0",              # PyTorch
"torch-geometric>=2.4.0",    # GNN libraries
"scipy>=1.10.0",             # Sparse matrices
```

**Recommendation**:
```toml
[project.optional-dependencies]
graph-ml = [
    "torch>=2.1.0",
    "torch-geometric>=2.4.0",
    "scipy>=1.10.0",
]
```

---

### Phase 3 Requirements (Month 2-3)

#### For Advanced Uncertainty:
```python
# Bayesian methods - NEEDED
"torch>=2.1.0",              # PyTorch for BNN
"pyro-ppl>=1.9.0",           # Pyro for Bayesian inference
"scipy>=1.10.0",             # Statistical functions
```

**Recommendation**:
```toml
[project.optional-dependencies]
bayesian = [
    "torch>=2.1.0",
    "pyro-ppl>=1.9.0",
    "scipy>=1.10.0",
]
```

#### For Active Learning:
```python
# Optimization - NEEDED
"scipy>=1.10.0",             # Optimization algorithms
"numpy>=1.24.0",             # Array operations
```

**Verdict**: Already covered by numpy/scipy

---

### Phase 4 Requirements (Month 4-6)

#### For Advanced ML:
```python
# Additional libraries
"lightning>=2.1.0",          # Training framework
"wandb>=0.16.0",             # Experiment tracking
"optuna>=3.5.0",             # Hyperparameter optimization
"accelerate>=0.24.0",        # Distributed training
```

**Recommendation**:
```toml
[project.optional-dependencies]
advanced-ml = [
    "lightning>=2.1.0",
    "wandb>=0.16.0",
    "optuna>=3.5.0",
    "accelerate>=0.24.0",
]
```

---

## ðŸŽ¯ Recommended Dependency Strategy

### Minimal Set (Phase 1 - Core Implementation)

Add only what's needed for immediate value:

```toml
[project]
dependencies = [
    "neo4j>=5.26.0",
    "redis>=7.1.0",
    "fastmcp>=2.14.1",
    "langchain>=1.2.0",
    "langchain-openai>=1.1.0",
    "langchain-neo4j>=0.6.0",
    "langgraph>=1.0.5",
    "uvicorn[standard]>=0.32.0",
    "fastapi>=0.121.0",
    "httpx>=0.26.0",
    "pydantic-settings>=2.6.0",
    "pytest>=8.0.0",
    "pytest-asyncio>=0.23.0",
    "python-dotenv>=1.0.0",
    "numpy>=1.24.0",                    # â­ NEW - For math operations
]

[project.optional-dependencies]
ml = [
    "torch>=2.1.0",                     # For ML models
    "transformers>=4.35.0",             # For BERT
    "datasets>=2.14.0",
    "scikit-learn>=1.3.0",
    "torch-geometric>=2.4.0",           # For GNNs
    "scipy>=1.10.0",
    "pyro-ppl>=1.9.0",                  # For Bayesian
]

dev = [
    "black>=23.0.0",
    "flake8>=6.0.0",
    "mypy>=1.5.0",
]
```

### Installation Commands:

```bash
# Phase 1 - Core (immediate)
cd backend
uv pip install numpy>=1.24.0

# Phase 2 - ML (Month 1)
uv pip install torch transformers datasets scikit-learn torch-geometric scipy

# Phase 3 - Advanced (Month 2-3)
uv pip install pyro-ppl scipy

# Or install all at once
uv sync --all-extras
```

---

## ðŸ’¡ Key Insights

### What We Already Have (REALLY GOOD!)

1. **Neo4j 5.26.0** âœ…
   - **HNSW support**: YES (since 5.13)
   - **GDS plugin**: Can be enabled
   - **Vector indexing**: Built-in

2. **LangChain** âœ…
   - Can integrate with BERT fine-tuning
   - Supports custom embeddings
   - Good foundation for KG construction

3. **FastAPI + Pydantic** âœ…
   - Easy to add new endpoints
   - Type-safe APIs for scientific algorithms
   - Good for uncertainty tracking APIs

4. **Redis** âœ…
   - Can cache similarity results
   - Store temporary uncertainty distributions
   - Speed up repeated queries

### What We Need (MINIMAL ADDITION)

1. **numpy** (Phase 1) - **ONLY NEW DEPENDENCY**
   - Used for: HNSW, calibration, uncertainty math
   - Standard in ML projects
   - No conflicts expected

2. **torch + transformers** (Phase 2)
   - Only needed when starting ML work
   - Can be installed separately
   - Large download (~2GB)

3. **torch-geometric** (Phase 2-3)
   - For RGCN and GNNs
   - Requires torch
   - Install when ready for graph ML

### What We DON'T Need (yet)

- **scipy**: Can use numpy for now (simpler)
- **pyro-ppl**: Can implement basic Bayesian methods manually
- **wandb/optuna**: Use simple file logging initially
- **accelerate**: Only for distributed training

---

## ðŸš€ Implementation Path

### Week 1: HNSW + Uncertainty (NO NEW DEPS!)
```python
# Use only: numpy (new), built-in Python
# Files: backend/app/science/similarity.py, uncertainty.py
```

### Month 1: BERT + ComplEx (ADD ML DEPS)
```python
# Add: torch, transformers, scikit-learn
# Files: backend/app/science/ml_models.py
```

### Month 2-3: Advanced (ADD GNN DEPS)
```python
# Add: torch-geometric, scipy
# Files: backend/app/science/gnn_models.py
```

### Month 4-6: Production (ADD TOOLS)
```python
# Add: pyro-ppl, wandb, optuna
# Files: backend/app/science/bayesian.py, experiments.py
```

---

## ðŸ“Š Dependency Management Strategy

### Option 1: Incremental Installation (RECOMMENDED)

```bash
# Day 1: Core scientific algorithms
uv pip install numpy

# Month 1: When starting ML
uv pip install torch transformers scikit-learn

# Month 2: When starting GNNs
uv pip install torch-geometric scipy

# Month 3: When starting Bayesian
uv pip install pyro-ppl
```

### Option 2: All at Once (SIMPLER)

```bash
# All dependencies at once
uv sync --all-extras
```

**Note**: Large download (~3-5GB) but simpler

### Option 3: Feature Flags (ADVANCED)

```python
# In code
try:
    import torch
    HAS_TORCH = True
except ImportError:
    HAS_TORCH = False
    # Fallback to simple methods
```

---

## âœ… Summary

### Current Status
- **80% of Phase 1 deps**: Already available
- **90% of core deps**: Built-in Python or existing
- **Missing**: Only numpy for Phase 1

### Action Items
1. **Immediate**: Add numpy to pyproject.toml
2. **Month 1**: Add torch, transformers when ready
3. **Month 2**: Add torch-geometric for GNNs
4. **Month 3**: Add pyro-ppl for Bayesian

### Expected Impact
- **Week 1**: 6 days for 10-100Ã— improvement
- **Cost**: Minimal (mostly compute, not packages)
- **Complexity**: Low (small dependency list)

**The project is in great shape for scientific implementation!** ðŸŽ‰